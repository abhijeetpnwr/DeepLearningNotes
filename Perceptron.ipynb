{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "![Perceptron](https://d17h27t6h515a5.cloudfront.net/topher/2017/January/5873fd05_simple-nn/simple-nn.png)\n",
    "\n",
    "Now you've seen how a simple neural network makes decisions: by taking in input data, processing that information, and finally, producing an output in the form of a decision! Let's take a deeper dive into the university admission example and learn more about how this input data is processed.\n",
    "\n",
    "Data, like test scores and grades, is fed into a network of interconnected nodes. These individual nodes are called perceptrons or neurons, and they are the basic unit of a neural network. Each one looks at input data and decides how to categorize that data. In the example above, the input either passes a threshold for grades and test scores or doesn't, and so the two categories are: yes (passed the threshold) and no (didn't pass the threshold). These categories then combine to form a decision -- for example, if both nodes produce a \"yes\" output, then this student gains admission into the university.\n",
    "\n",
    "\n",
    "![eample](https://d17h27t6h515a5.cloudfront.net/topher/2017/January/588160fe_plot-perceptron-combine-v2/plot-perceptron-combine-v2.png)\n",
    "\n",
    "\n",
    "Let's zoom in even further and look at how a single perceptron processes input data.\n",
    "\n",
    "The perceptron above is one of the two perceptrons from the video that help determine whether or not a student is accepted to a university. It decides whether a student's grades are high enough to be accepted to the university. You might be wondering: \"How does it know whether grades or test scores are more important in making this acceptance decision?\" Well, when we initialize a neural network, we don't know what information will be most important in making a decision. It's up to the neural network to learn for itself which data is most important and adjust how it considers that data.\n",
    "\n",
    "It does this with something called weights.\n",
    "\n",
    "Weights\n",
    "When input data comes into a perceptron, it gets multiplied by a weight value that is assigned to this particular input. For example, the perceptron above have two inputs, tests for test scores and grades, so it has two associated weights that can be adjusted individually. These weights start out as random values, and as the neural network network learns more about what kind of input data leads to a student being accepted into a university, the network adjusts the weights based on any errors in categorization that the previous weights resulted in. This is called training the neural network.\n",
    "\n",
    "A higher weight means the neural network considers that input more important than other inputs, and lower weight means that the data is considered less important. An extreme example would be if test scores had no affect at all on university acceptance; then the weight of the test score input data would be zero and it would have no affect on the output of the perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights\n",
    "When input data comes into a perceptron, it gets multiplied by a weight value that is assigned to this particular input. For example, the perceptron above have two inputs, tests for test scores and grades, so it has two associated weights that can be adjusted individually. These weights start out as random values, and as the neural network network learns more about what kind of input data leads to a student being accepted into a university, the network adjusts the weights based on any errors in categorization that the previous weights resulted in. This is called training the neural network.\n",
    "\n",
    "A higher weight means the neural network considers that input more important than other inputs, and lower weight means that the data is considered less important. An extreme example would be if test scores had no affect at all on university acceptance; then the weight of the test score input data would be zero and it would have no affect on the output of the perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summing the Input Data\n",
    "So, each input to a perceptron has an associated weight that represents its importance and these weights are determined during the learning process of a neural network, called training. In the next step, the weighted input data is summed up to produce a single value, that will help determine the final output - whether a student is accepted to a university or not. Let's see a concrete example of this.\n",
    "\n",
    "![weights](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/5894d4d5_perceptron-graphics.001/perceptron-graphics.001.jpeg)\n",
    "\n",
    "When writing equations related to neural networks, the weights will always be represented by some type of the letter w. It will usually look like a W when it represents a matrix of weights or a w when it represents an individual weight, and it may include some additional information in the form of a subscript to specify which weights (you'll see more on that next). But remember, when you see the letter w, think weights.\n",
    "\n",
    "In this example, we'll use w\n",
    "​grades\n",
    "​​  for the weight of grades and w\n",
    "​test\n",
    "​​  for the weight of test. For the image above, let's say that the weights are: w\n",
    "​grades\n",
    "​​ =−1,w\n",
    "​test\n",
    "​​  =−0.2. You don't have to be concerned with the actual values, but their relative values are important. w\n",
    "​grades\n",
    "​​  is 5 times larger than w\n",
    "​test\n",
    "​​ , which means the neural network considers grades input 5 times more important than test in determining whether a student will be accepted into a university.\n",
    "\n",
    "The perceptron applies these weights to the inputs and sums them in a process known as linear combination. In our case, this looks like w\n",
    "​grades\n",
    "​​ ⋅x\n",
    "​grades\n",
    "​​ +w\n",
    "​test\n",
    "​​ ⋅x\n",
    "​test\n",
    "​​ =−1⋅x\n",
    "​grades\n",
    "​​ −0.2⋅x\n",
    "​test\n",
    "​​ .\n",
    "\n",
    "Now, to make our equation less wordy, let's replace the explicit nam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to make our equation less wordy, let's replace the explicit names with numbers. Let's use 1 for grades and 2 for tests. So now our equation becomes\n",
    "\n",
    "w\n",
    "​1\n",
    "​​ ⋅x\n",
    "​1\n",
    "​​ +w\n",
    "​2\n",
    "​​ ⋅x\n",
    "​2\n",
    "​​ \n",
    "\n",
    "In this example, we just have 2 simple inputs: grades and tests. Let's imagine we instead had m different inputs and we labeled them x\n",
    "​1\n",
    "​​ ,x\n",
    "​2\n",
    "​​ ,...,x\n",
    "​m\n",
    "​​ . Let's also say that the weight corresponding to x\n",
    "​1\n",
    "​​  is w\n",
    "​1\n",
    "​​  and so on. In that case, we would express the linear combination succintly as:\n",
    "\n",
    "∑\n",
    "​i=1\n",
    "​m\n",
    "​​ w\n",
    "​i\n",
    "​​ ⋅x\n",
    "​i\n",
    "​​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the Output with an Activation Function\n",
    "Finally, the result of the perceptron's summation is turned into an output signal! This is done by feeding the linear combination into an activation function.\n",
    "\n",
    "One of the simplest activation functions is the Heaviside step function. This function returns a 0 if the linear combination is less than 0. It returns a 1 if the linear combination is positive or equal to zero. The Heaviside step function is shown below, where h is the calculated linear combination:\n",
    "![activte function](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/5894da51_heaviside-2/heaviside-2.png)\n",
    "\n",
    "![perceptron eq](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/5895102f_heaviside-step-function-2/heaviside-step-function-2.gif)\n",
    "\n",
    "In the university acceptance example above, we used the weights w\n",
    "​grades\n",
    "​​ =−1,w\n",
    "​test\n",
    "​​  =−0.2. Since w\n",
    "​grades\n",
    "​​  and w\n",
    "​test\n",
    "​​  are negative values, the activation function will only return a 1 if grades and test are 0! This is because the range of values from the linear combination using these weights and inputs are (−∞,0] (i.e. negative infinity to 0, including 0 itself).\n",
    "\n",
    "Since we know we want more than one possible grade/test combination to result in acceptance, we need to adjust the inputs to our activation function so it accepts more scores. Specifically, we need all the scores we’d like to accept to enter the step function with values greater than or equal to zero. One way to do that is by adding a value to our linear combination, called a bias.\n",
    "\n",
    "A bias, represented in equations as b, lets us move values in one direction or another.\n",
    "\n",
    "For example, to graph a simple straight line passing through the origin (0,0) with a slope of 1, we can use the equation y=x. In order to move that line up so it has the same slope but passes through the y-axis at y=2, we could add a bias value of 2 to the equation, giving us y=x+2.\n",
    "\n",
    "Of course, with neural networks we won't know in advance what values to pick for biases. That’s ok, because just like the weights, the bias can also be updated and changed by the neural network during training. So after adding a bias, we now have a complete perceptron formula:\n",
    "\n",
    "![Perceptron formulae](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/58951180_perceptron-equation-2/perceptron-equation-2.gif)\n",
    "\n",
    "This formula returns 1 if the input (x\n",
    "​1\n",
    "​​ ,x\n",
    "​2\n",
    "​​ ,...,x\n",
    "​m\n",
    "​​ ) belongs to the accepted-to-university category or returns 0 if it doesn't. The input is made up of one or more real numbers, each one represented by x\n",
    "​i\n",
    "​​ , where m is the number of inputs.\n",
    "\n",
    "Then the neural network starts to learn! Initially, the weights (w\n",
    "​i\n",
    "​​ ) and bias (b) are assigned a random value, and then they are updated using a learning algorithm like gradient descent. The weights and biases change so that the next training example is more accurately categorized, and patterns in data are \"learned\" by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
